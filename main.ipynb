{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(1, 'Cluster/')\n",
    "\n",
    "from data_load import *\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = import_Gaia_data(\"data/type2.csv\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.clf()\n",
    "plt.scatter (np.sin (data.positions[:,1]) , data.proper_motions_err[:,0]/numpy.cos(data.positions[:,1]))\n",
    "plt.savefig(\"bug.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data conversion and coordinates change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change positions from deg to rad\n",
    "\n",
    "data.positions = deg_to_rad (data.positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change proper motions from mas/yr to rad/s\n",
    "\n",
    "data.proper_motions = data.proper_motions * 1.5362818500441604e-16\n",
    "data.proper_motions_err = data.proper_motions_err * 1.5362818500441604e-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate covariance matrix and its inverse\n",
    "\n",
    "data.covariance = covariant_matrix ( data.proper_motions_err , data.proper_motions_err_corr )\n",
    "\n",
    "data.covariance_inv = numpy.linalg.inv ( data.covariance )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate Cartesian positions\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, 'Cluster/')\n",
    "\n",
    "from CoordinateTransformations import *\n",
    "\n",
    "data.positions_Cartesian = geographic_to_Cartesian_point ( data.positions )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change proper motions from (ra,dec) to Cartesian coordinates\n",
    "\n",
    "#data3.proper_motions = tangent_geographic_to_Cartesian2 (data3.positions , data3.proper_motions)\n",
    "#data3.proper_motions_err = tangent_geographic_to_Cartesian2 (data3.positions , data3.proper_motions_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change positions from (ra,dec) to Cartesian\n",
    "\n",
    "#data3.positions = geographic_to_Cartesian (data3.positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating random VSH coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from VectorSphericalHarmonicsVectorized import VectorSphericalHarmonicE, VectorSphericalHarmonicB\n",
    "\n",
    "def random_aQlm_coeffs ( lmax , lower_bound , upper_bound ):\n",
    "    negative_coeffs = [ [ random.uniform ( lower_bound , upper_bound ) + 1j * random.uniform ( lower_bound , upper_bound ) for m in range ( -l , 0 ) ] for l in range ( 1 , lmax + 1 ) ]\n",
    "    \n",
    "    coeffs = [ [ negative_coeffs[ l-1 ][ m+l ] if m < 0\n",
    "                 else random.uniform ( lower_bound , upper_bound ) + 1j * 0.0 if m == 0\n",
    "                 else (-1) ** m * numpy.conj ( negative_coeffs[ l-1 ][ m-l ] )\n",
    "                 for m in range ( -l , l+1 ) ] for l in range ( 1 , lmax + 1 ) ]\n",
    "    \n",
    "    return coeffs\n",
    "\n",
    "def random_vsh_coeffs ( lmax , lower_bound , upper_bound):\n",
    "    vsh_E_coeffs = random_aQlm_coeffs ( lmax , lower_bound , upper_bound )\n",
    "    vsh_B_coeffs = random_aQlm_coeffs ( lmax , lower_bound , upper_bound )\n",
    "        \n",
    "    return vsh_E_coeffs , vsh_B_coeffs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vsh_E_coeffs , vsh_B_coeffs = random_vsh_coeffs ( 2 , -1.0e-15 , 1.0e-15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from CoordinateTransformations import *\n",
    "\n",
    "Lmax = 1\n",
    "\n",
    "par = {}\n",
    "\n",
    "for l in numpy.arange(1,Lmax+1):\n",
    "    for m in numpy.arange(0, l+1):\n",
    "        if m==0:\n",
    "            par['Re_a^E_'+str(l)+'0'] = 0\n",
    "            par['Re_a^B_'+str(l)+'0'] = 0\n",
    "        else:\n",
    "            par['Re_a^E_'+str(l)+str(m)] = 0\n",
    "            par['Im_a^E_'+str(l)+str(m)] = 0\n",
    "            par['Re_a^B_'+str(l)+str(m)] = 0\n",
    "            par['Im_a^B_'+str(l)+str(m)] = 0\n",
    "            \n",
    "VSH_bank = {}\n",
    "\n",
    "for l in range ( 1 , Lmax + 1 ):\n",
    "    VSH_bank['Re[Y^E_' + str(l) + '0]'] = Cartesian_to_geographic_vector (data.positions_Cartesian , numpy.real ( VectorSphericalHarmonicE ( l , 0 , data.positions_Cartesian ) ) )\n",
    "        \n",
    "    VSH_bank['Re[Y^B_' + str(l) + '0]'] = Cartesian_to_geographic_vector (data.positions_Cartesian , numpy.real ( VectorSphericalHarmonicB ( l , 0 , data.positions_Cartesian ) ) )\n",
    "    \n",
    "    for m in range ( 1 , l + 1 ):\n",
    "        VSH_bank['Re[Y^E_' + str(l) + str(m) + ']'] = Cartesian_to_geographic_vector (data.positions_Cartesian , numpy.real ( VectorSphericalHarmonicE ( l , m , data.positions_Cartesian ) ) )\n",
    "        \n",
    "        VSH_bank['Im[Y^E_' + str(l) + str(m) + ']'] = Cartesian_to_geographic_vector (data.positions_Cartesian , numpy.imag ( VectorSphericalHarmonicE ( l , m , data.positions_Cartesian ) ) )\n",
    "        \n",
    "        VSH_bank['Re[Y^B_' + str(l) + str(m) + ']'] = Cartesian_to_geographic_vector (data.positions_Cartesian , numpy.real ( VectorSphericalHarmonicB ( l , m , data.positions_Cartesian ) ) )\n",
    "        \n",
    "        VSH_bank['Im[Y^B_' + str(l) + str(m) + ']'] = Cartesian_to_geographic_vector (data.positions_Cartesian , numpy.imag ( VectorSphericalHarmonicB ( l , m , data.positions_Cartesian ) ) )\n",
    "\n",
    "def generate_model ( coeffs , VSH_bank ):\n",
    "    v_Q = numpy.sum ( [ numpy.sum ( [ \n",
    "                        coeffs['Re_a^' + Q + '_' + str(l) + '0'] * VSH_bank['Re[Y^' + Q + '_' + str(l) + '0]'] \n",
    "                        + 2 * numpy.sum ( [ \n",
    "                        coeffs['Re_a^' + Q + '_'+str(l)+str(m)] * VSH_bank['Re[Y^' + Q + '_' + str(l) + str(m) + ']'] \n",
    "                        - coeffs['Im_a^'+ Q + '_'+str(l)+str(m)] * VSH_bank['Im[Y^' + Q + '_' + str(l) + str(m) + ']'] \n",
    "                        for m in range ( 1 , l + 1 ) ] )\n",
    "                    for l in range ( 1 , Lmax + 1 ) ] )\n",
    "                for Q in [ 'E' , 'B' ] ] )\n",
    "        \n",
    "    return v_Q\n",
    "\n",
    "\n",
    "generate_model ( par , VSH_bank )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = generate_model ( vsh_E_coeffs , vsh_B_coeffs , data3.positions )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def covariant_matrix ( errors , corr ):\n",
    "    covariant_matrix = numpy.einsum ( '...i,...j->...ij' , errors , errors )\n",
    "    \n",
    "    covariant_matrix[...,0,1] = covariant_matrix[...,1,0] = numpy.multiply ( covariant_matrix[...,1,0] , corr.flatten() )\n",
    "    return covariant_matrix\n",
    "\n",
    "def R_values ( pm , pm_err , pm_err_corr , model ):\n",
    "    covariant_matrices = covariant_matrix ( pm_err , pm_err_corr )\n",
    "    \n",
    "    M = pm - model\n",
    "    \n",
    "    R_values = numpy.einsum ( '...i,...ij,...j->...' , M , numpy.linalg.inv ( covariant_matrices ) , M ) \n",
    "        \n",
    "    return R_values\n",
    "\n",
    "def compute_log_likelihood ( R_values ):\n",
    "    log_likelihood = numpy.log ( ( 1. - numpy.exp ( - R_values ** 2 / 2.) ) / ( R_values ** 2 ) ).sum()\n",
    "    \n",
    "    return log_likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-27058.36292655995"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = R_values ( data3.proper_motions , data3.proper_motions_err , data3.proper_motions_err_corr , model)\n",
    "\n",
    "u = compute_log_likelihood (R)\n",
    "\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re[a^E_21] Re[a^E_11]\n",
      "Im[a^E_21] Im[a^E_11]\n",
      "Re[a^B_11] Im[a^E_11]\n",
      "Im[a^B_11] Re[a^E_11]\n",
      "Im[a^B_11] Re[a^E_21]\n",
      "Re[a^B_21] Im[a^E_11]\n",
      "Re[a^B_21] Re[a^B_11]\n",
      "Im[a^B_21] Im[a^B_11]\n",
      "-0.18013151269390593\n"
     ]
    }
   ],
   "source": [
    "points_Cart = geographic_to_Cartesian_point ( data.positions )\n",
    "\n",
    "from VectorSphericalHarmonicsVectorized import VectorSphericalHarmonicE, VectorSphericalHarmonicB\n",
    "\n",
    "n_objects = points_Cart.shape[0]\n",
    "\n",
    "prefactor = 4 * numpy.pi / n_objects\n",
    "\n",
    "import numpy as np\n",
    "names = []\n",
    "F = {}\n",
    "\n",
    "\n",
    "Lmax = 2\n",
    "\n",
    "l_range = numpy.arange(1,Lmax+1)\n",
    "\n",
    "for Q in [ 'E' , 'B' ]:\n",
    "    for l in np.arange(1, Lmax+1):\n",
    "        for m in np.arange(0, l+1):\n",
    "            if m == 0:\n",
    "                names += [ 'Re[a^' + Q + '_' + str(l) + str(m) + ']' ]\n",
    "\n",
    "            else:\n",
    "                names += [ 'Re[a^' + Q + '_' + str(l) + str(m) + ']' ]\n",
    "                names += [ 'Im[a^' + Q + '_' + str(l) + str(m) + ']' ]\n",
    "                \n",
    "matrix = np.zeros( (len(names), len(names)) )        \n",
    "        \n",
    "for i, n_x in enumerate(names):\n",
    "    part_x = n_x.split('^')[0][0]\n",
    "    Q_x = n_x.split('^')[1][0]\n",
    "    l_x = int(n_x.split('^')[1][2])\n",
    "    m_x = int(n_x.split('^')[1][3])\n",
    "    \n",
    "    for j, n_y in enumerate(names):\n",
    "        part_y = n_y.split('^')[0][0]\n",
    "        Q_y = n_y.split('^')[1][0]\n",
    "        l_y = int(n_y.split('^')[1][2])\n",
    "        m_y = int(n_y.split('^')[1][3])\n",
    "        \n",
    "        X = VectorSphericalHarmonicE ( l_x , m_x , points_Cart ) if Q_x=='E' else VectorSphericalHarmonicB ( l_x , m_x , points_Cart )\n",
    "        X = np.real(X) if part_x=='R' else np.imag(X)\n",
    "        \n",
    "        Y = VectorSphericalHarmonicE ( l_y , m_y , points_Cart ) if Q_y=='E' else VectorSphericalHarmonicB ( l_y , m_y , points_Cart )\n",
    "        Y = np.real(Y) if part_y=='R' else np.imag(Y)\n",
    "        \n",
    "        matrix[i,j] = prefactor * numpy.einsum ( \"...j,...j->...\" , X , Y ).sum()\n",
    "        \n",
    "plt.clf()\n",
    "plt.imshow(matrix)\n",
    "plt.colorbar()\n",
    "plt.savefig(\"matrix.pdf\")\n",
    "plt.clf()\n",
    "\n",
    "corr = []\n",
    "for i in range(len(matrix)):\n",
    "    for j in range(i):\n",
    "        x = matrix[i,j]/np.sqrt(matrix[i,i]*matrix[j,j])\n",
    "        corr.append(x)\n",
    "        if abs(x)>0.14:\n",
    "            print(names[i], names[j])\n",
    "corr = np.array(corr)\n",
    "plt.hist(corr)\n",
    "plt.savefig(\"hist.png\")\n",
    "\n",
    "i = names.index('Im[a^E_11]')\n",
    "j = names.index('Re[a^B_21]')\n",
    "x = matrix[i,j]/np.sqrt(matrix[i,i]*matrix[j,j])\n",
    "print (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to fit with Chris' Python Particle Swarm Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(-4.051820432552491e-15+3.9019242260068935e-15j), 1.0962514403063393e-15, (-2.1989423583619877e-15+1.5898338470668441e-15j)], [(-4.005078512411002e-15+8.295448331349153e-15j), (7.242640554933391e-15-7.022912072523901e-15j), 7.407801139573162e-16, (-5.394325112551346e-15+9.140480362437914e-15j), (-3.866305737185125e-15-1.4372516862603125e-15j)], [(9.905129645633751e-15-1.2045374537853373e-15j), (-4.591105300268807e-15+1.6206152525940413e-16j), (-1.4651795083578574e-15-2.3169299929584544e-15j), 2.00678369665432e-15, (8.961771647529057e-15-3.435506878025172e-15j), (-2.777910391239437e-15-6.516987950664284e-15j), (-7.6636705852496e-15+1.4687411361732721e-15j)]]\n",
      "[[(-4.86130129408709e-15+9.746539081626012e-15j), 1.7986352892125863e-15, (7.270009629945627e-15-2.0299349018935748e-15j)], [(-3.490502032823688e-15-1.715352162705143e-15j), (-4.862114468593031e-15-5.833711376264423e-15j), -8.561320209723371e-15, (4.63599678108349e-15+5.5491893756491685e-15j), (-8.754921473469426e-15+7.541946507125891e-15j)], [(-6.06436128305591e-15-2.044497183993133e-15j), (-5.9212581389419875e-15+9.964970394079958e-15j), (-8.91459631296432e-16+9.983613229563222e-15j), 1.9283964172857136e-15, (8.6417214312764e-15+5.626168777821809e-16j), (2.5465820280464594e-15-9.176476560049593e-15j), (7.344734390929407e-15-8.865020851237762e-15j)]]\n",
      "[[(-3.953198753144274e-15+4.0240320254038886e-15j), 1.1325412971204566e-15, (-2.273398990741118e-15+1.6302270539766253e-15j)], [(-4.059246270266352e-15+8.492088518425572e-15j), (7.370694386535324e-15-7.020836389062327e-15j), 5.679931021086122e-16, (-5.277176523961337e-15+9.07701996218693e-15j), (-3.871678896744584e-15-1.3938349621385926e-15j)], [(9.72472305919479e-15-1.2401940439975548e-15j), (-4.784025108512949e-15+3.4526139011449444e-16j), (-1.6326869608705156e-15-2.162699768952619e-15j), 1.887776110162597e-15, (9.04236558956181e-15-3.460743289079959e-15j), (-2.9453038363439615e-15-6.5909092369568205e-15j), (-7.852393563608727e-15+1.5530218701371385e-15j)]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fff38954ec7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m                 EnergyTol = 1.0e-8)\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mmyswarm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/deyanmihaylov/anaconda/lib/python3.5/site-packages/PySO/Swarm.py\u001b[0m in \u001b[0;36mRun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mContinueCondition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvolveSwarm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvolutionCounter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_periodic_checkpoint\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/deyanmihaylov/anaconda/lib/python3.5/site-packages/PySO/Swarm.py\u001b[0m in \u001b[0;36mEvolveSwarm\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;31m# Update function values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mValues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_posterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# Update particle's best known position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/deyanmihaylov/anaconda/lib/python3.5/site-packages/PySO/Model.py\u001b[0m in \u001b[0;36mlog_posterior\u001b[0;34m(self, param)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mlog_prior\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlog_likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \"\"\"\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-fff38954ec7a>\u001b[0m in \u001b[0;36mlog_likelihood\u001b[0;34m(self, param)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvsh_E_coeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_model\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvsh_E_coeffs\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvsh_B_coeffs\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdata3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_R\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mdata3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproper_motions\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdata3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproper_motions_err\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdata3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproper_motions_err_corr\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlog_likelhood_fun\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2ea5c153bc8f>\u001b[0m in \u001b[0;36mgenerate_model\u001b[0;34m(vsh_E_coeffs, vsh_B_coeffs, positions)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mv_B\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlm_coeff\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mVectorSphericalHarmonicB\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpoint_Cart\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_almost_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_E\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/deyanmihaylov/Desktop/Astrometry/Quasars/QuasarProperMotions/VectorSphericalHarmonics.py\u001b[0m in \u001b[0;36mVectorSphericalHarmonicB\u001b[0;34m(l, m, n)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         DY_Dtheta = -( c1 * NormalisedAssociatedLegendrePolynomial ( l , m-1 , x ) - \n\u001b[0m\u001b[1;32m    130\u001b[0m                      c2 * NormalisedAssociatedLegendrePolynomial ( l , m+1 , x ) ) * np.exp ( (1j) * m * phi )\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import PySO\n",
    "\n",
    "class QSO_VSH_fit(PySO.Model):\n",
    "\n",
    "    Lmax = 3\n",
    "    \n",
    "    names=[]\n",
    "    for L in numpy.arange(1, Lmax+1):\n",
    "        for m in numpy.arange(-L, L+1):\n",
    "            if m==0:\n",
    "                names += ['Ra^E_{0}_{1}'.format(L,m)]\n",
    "                names += ['Ra^B_{0}_{1}'.format(L,m)]\n",
    "            else:\n",
    "                names += ['Ra^E_{0}_{1}'.format(L,m)]\n",
    "                names += ['Ra^B_{0}_{1}'.format(L,m)]\n",
    "                names += ['Ia^E_{0}_{1}'.format(L,m)]\n",
    "                names += ['Ia^B_{0}_{1}'.format(L,m)]\n",
    "    \n",
    "    bounds = [ [-1.0e-14,1.0e-14] for i in range(len(names))]\n",
    "    \n",
    "\n",
    "    def log_likelihood(self, param):\n",
    "        \n",
    "        vsh_E_coeffs = [ [ \n",
    "                            param['Ra^E_{0}_{1}'.format(L,m)] \n",
    "                            if m==0 else \n",
    "                            param['Ra^E_{0}_{1}'.format(L,m)]+(1j)*param['Ia^E_{0}_{1}'.format(L,m)]\n",
    "                          for m in numpy.arange(-L, L+1) ] for L in numpy.arange(1, self.Lmax+1)]\n",
    "        \n",
    "        vsh_B_coeffs = [ [ \n",
    "                            param['Ra^B_{0}_{1}'.format(L,m)] \n",
    "                            if m==0 else \n",
    "                            param['Ra^B_{0}_{1}'.format(L,m)]+(1j)*param['Ia^B_{0}_{1}'.format(L,m)]\n",
    "                          for m in numpy.arange(-L, L+1) ] for L in numpy.arange(1, self.Lmax+1)]\n",
    "        \n",
    "        print (vsh_E_coeffs)\n",
    "        \n",
    "        model = generate_model (vsh_E_coeffs , vsh_B_coeffs , data3.positions)\n",
    "        R = generate_R ( data3.proper_motions , data3.proper_motions_err , data3.proper_motions_err_corr , model)\n",
    "        return log_likelhood_fun (R)\n",
    "    \n",
    "mymodel = QSO_VSH_fit()\n",
    "\n",
    "NumParticles = 2\n",
    "\n",
    "myswarm = PySO.Swarm(mymodel,\n",
    "                NumParticles,\n",
    "                Omega = 0.01,\n",
    "                PhiP = 0.1,\n",
    "                PhiG = 0.1,\n",
    "                EnergyTol = 1.0e-8)\n",
    "\n",
    "myswarm.Run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0029944289999548346"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "timeit.timeit('\"-\".join(str(n) for n in range(100))', number=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "def plot_pm_err_ellipse (pm , pm_err , pm_err_corr):\n",
    "    i = 575\n",
    "    \n",
    "    covariance_matrix = numpy.array ( [ [ pm_err[i,0] * pm_err[i,0] , pm_err_corr[i] * pm_err[i,0] * pm_err[i,1] ],\n",
    "                                        [ pm_err_corr[i] * pm_err[i,1] * pm_err[i,0] , pm_err[i,1] * pm_err[i,1] ] ] )\n",
    "    \n",
    "    eigenvalues , eigenvectors = numpy.linalg.eig ( covariance_matrix )\n",
    "    \n",
    "    box_size = numpy.max ( [ numpy.sqrt(eigenvalues[0]) , numpy.sqrt(eigenvalues[1]) , numpy.linalg.norm ( pm[i] ) ] )\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.axes().set_aspect('equal')\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    plt.xlim ( [ pm[i,0] - 1.5 * box_size , pm[i,0] + 1.5 * box_size ] )\n",
    "    plt.ylim ( [ pm[i,1] - 1.5 * box_size , pm[i,1] + 1.5 * box_size ] )\n",
    "    \n",
    "    plt.arrow(0 , 0 , pm[i,0] , pm[i,1] , width=box_size * 1e-3 , head_width=box_size * 0.5e-1, head_length=box_size * 1e-1 , color='k')\n",
    "            \n",
    "    plt.arrow(pm[i,0] , pm[i,1] , numpy.sqrt(eigenvalues[0]) * eigenvectors[0,0] , numpy.sqrt(eigenvalues[0]) * eigenvectors[0,1] , width=box_size * 1e-3 , head_width=box_size * 0.5e-1, head_length=box_size * 1e-1 , color='orange')\n",
    "    \n",
    "    plt.arrow(pm[i,0] , pm[i,1] , numpy.sqrt(eigenvalues[1]) * eigenvectors[1,0] , numpy.sqrt(eigenvalues[1]) * eigenvectors[1,1] , width=box_size * 1e-3 , head_width=box_size * 0.5e-1, head_length=box_size * 1e-1 , color='y')\n",
    "    \n",
    "    angle = - numpy.rad2deg ( numpy.arctan2 ( eigenvectors[1,0] , eigenvectors[1,1] ) )\n",
    "            \n",
    "    ell = Ellipse(xy=(pm[i,0] , pm[i,1]), width=2 * numpy.sqrt(eigenvalues[0]), height=2 * numpy.sqrt(eigenvalues[1]), angle = angle)\n",
    "    \n",
    "    ax.add_patch(ell)\n",
    "    ax.set_aspect('equal')\n",
    "            \n",
    "    plt.show()\n",
    "    \n",
    "    return covariance_matrix\n",
    "\n",
    "print (plot_pm_err_ellipse ( data3.proper_motions , data3.proper_motions_err , data3.proper_motions_err_corr ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_pos = type3_sample\n",
    "final_pos = type3_sample + type3_sample_pm\n",
    "\n",
    "lines_to_plot = []\n",
    "\n",
    "for i,_ in enumerate (initial_pos):\n",
    "    longs = numpy.linspace(initial_pos[i,0], final_pos[i,0], 10)\n",
    "    lats = numpy.linspace(initial_pos[i,1], final_pos[i,1], 10)\n",
    "    \n",
    "    line_m = GeographicToMollweide ( numpy.array ( [longs , lats] ).transpose() )\n",
    "    \n",
    "    lines_to_plot.append( line_m.transpose() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_pos_m = GeographicToMollweide ( initial_pos )\n",
    "final_pos_m = GeographicToMollweide ( final_pos )\n",
    "diff_m = final_pos_m - initial_pos_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "t = numpy.linspace (0, 2 * numpy.pi, 100)\n",
    "plt.plot ( 2 * numpy.sqrt(2) * numpy.cos(t) , numpy.sqrt(2) * numpy.sin(t) , linewidth=0.5 )\n",
    "\n",
    "for i,_ in enumerate(initial_pos_m):\n",
    "    plt.arrow( initial_pos_m[i,0] , initial_pos_m[i,1] , diff_m[i,0] , diff_m[i,1] , head_width=0.025, head_length=0.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spherepy as sp\n",
    "c = sp.random_coefs(4, 4) # generate some random coefficients\n",
    "print (type(c))\n",
    "# sp.pretty_coefs(c)\n",
    "# p = sp.ispht(c, 50, 50) # inverse spherical transform to pattern\n",
    "# sp.plot_sphere_mag(p) # plot the magnitude of the pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = import_Gaia_data(\"data/type2.csv\")\n",
    "\n",
    "def generate_scalar_bg (data):\n",
    "    scale = 1.0e-15\n",
    "    \n",
    "    vsh_E_coeffs = [[0j, 1.0 * scale + 0j, 0j], [0j, 0j, 0j, 0j, 0j]]\n",
    "    vsh_B_coeffs = [[0j, 0j, 0j], [0j, 0j, 0j, 0j, 0j]]\n",
    "    \n",
    "    model_pm = generate_model ( vsh_E_coeffs , vsh_B_coeffs , data.positions )\n",
    "    \n",
    "    data.proper_motions = model_pm\n",
    "\n",
    "    data.proper_motions_err = scale * numpy.ones(data.proper_motions_err.shape, dtype=None, order='C')\n",
    "    data.proper_motions_err_corr = numpy.zeros(data.proper_motions_err_corr.shape, dtype=None, order='C')\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = generate_scalar_bg (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[0j, 0j, 0j],\n",
       "  [(0.39117426637007136+0.05246644182931647j),\n",
       "   (0.3849564052479421+0j),\n",
       "   (-0.39117426637007136+0.05246644182931647j),\n",
       "   (-0.29143302476008554+0.465867197841277j),\n",
       "   (-0.23278436208940845+0.6225072674042416j)],\n",
       "  [(-0.2135549821259214-0.09954648419431493j),\n",
       "   (0.04950177680232255+0.2676525920743789j),\n",
       "   (-0.01912944381349385+0j),\n",
       "   (-0.04950177680232255+0.2676525920743789j),\n",
       "   (-0.2135549821259214+0.09954648419431493j),\n",
       "   (-0.03739210865090102+0.40833859706171516j),\n",
       "   (-0.22858766855986293+0.06058683254654202j)],\n",
       "  [(-0.06986339050675432-0.02375744420870127j),\n",
       "   (0.016620751983872945+0.05024161831349102j),\n",
       "   (-0.0006714160781631189-0.014726134286615442j),\n",
       "   (0.07834791920721844+0j),\n",
       "   (0.0006714160781631189-0.014726134286615442j),\n",
       "   (0.016620751983872945-0.05024161831349102j),\n",
       "   (0.06986339050675432-0.02375744420870127j),\n",
       "   (-0.16348014529248847-0.09658181326786355j),\n",
       "   (-0.0819806187521374+0.01268925213222059j)],\n",
       "  [(-0.034306741450575384+0.07165544354230163j),\n",
       "   (0.0243679182066645+0.03936227002326641j),\n",
       "   (0.07057950866226946+0.057754754900696675j),\n",
       "   (-0.024729635356047195+0.029055160205422197j),\n",
       "   (0.024197908390961777+0j),\n",
       "   (0.024729635356047195+0.029055160205422197j),\n",
       "   (0.07057950866226946-0.057754754900696675j),\n",
       "   (-0.0243679182066645+0.03936227002326641j),\n",
       "   (-0.034306741450575384-0.07165544354230163j),\n",
       "   (-0.005983674992250787+0.00985269388970486j),\n",
       "   (0.00559460969652663-0.024331765407585512j)]],\n",
       " [[0j, 0j, 0j],\n",
       "  [(-0.27046581887767096-0.22965238549556274j),\n",
       "   (-0.2166766159946109+0j),\n",
       "   (0.27046581887767096-0.22965238549556274j),\n",
       "   (0.7228294819700184+0.10456772450126821j),\n",
       "   (0.7676694790049201+0.01849704027927126j)],\n",
       "  [(0.2637133230594162+0.09426768227357024j),\n",
       "   (-0.20085808411410405+0.3629741719974492j),\n",
       "   (0.24158818017007094+0j),\n",
       "   (0.20085808411410405+0.3629741719974492j),\n",
       "   (0.2637133230594162-0.09426768227357024j),\n",
       "   (-0.23038672639728808+0.22628311504384302j),\n",
       "   (0.06909693868499565-0.32096978233849793j)],\n",
       "  [(0.007458676181743139-0.01816260783375995j),\n",
       "   (0.0410005098984268-0.02779210100364608j),\n",
       "   (-0.11923262890473746+0.058798123516649516j),\n",
       "   (0.22187080612282045+0j),\n",
       "   (0.11923262890473746+0.058798123516649516j),\n",
       "   (0.0410005098984268+0.02779210100364608j),\n",
       "   (-0.007458676181743139-0.01816260783375995j),\n",
       "   (0.002568303266362472+0.037109146611927254j),\n",
       "   (-0.12486537809213875+0.016860202363111143j)],\n",
       "  [(-0.059550860754226345-0.002601987534216114j),\n",
       "   (0.07530709285805366+0.0010777435052537932j),\n",
       "   (-0.05032300106095047+0.013049086103722353j),\n",
       "   (0.07072711616370253-0.022828457749136433j),\n",
       "   (0.0538940133025785+0j),\n",
       "   (-0.07072711616370253-0.022828457749136433j),\n",
       "   (-0.05032300106095047-0.013049086103722353j),\n",
       "   (-0.07530709285805366+0.0010777435052537932j),\n",
       "   (-0.059550860754226345+0.002601987534216114j),\n",
       "   (-0.07306452065711543+0.012512436884295977j),\n",
       "   (0.023809021198579396-0.026867342835543297j)]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = import_Gaia_data(\"data/type2.csv\")\n",
    "\n",
    "def generate_gr_bg (data):\n",
    "    scale = 1.0e-15\n",
    "\n",
    "    variance = numpy.array([ 0.0 , 0.3490658503988659 , 0.03490658503988659 , 0.006981317007977318 , 0.0019946620022792336 ])\n",
    "\n",
    "    vsh_E_coeffs = [ [ scale * (numpy.random.normal(0.0 , numpy.sqrt(variance[l-1])) + (1j) * numpy.random.normal(0.0 , numpy.sqrt(variance[l-1]))) for m in range (-l,l+1)] for l in range (1,len(variance)+1)]\n",
    "\n",
    "    for l , l_coeffs in enumerate(vsh_E_coeffs):\n",
    "        if l > 0:\n",
    "            for m in range (-l,l+1):\n",
    "                if m < 0:\n",
    "                    l_coeffs[m+l] = ((-1)**(-m)) * numpy.conj (l_coeffs[-m+l])\n",
    "                elif m == 0:\n",
    "                    l_coeffs[l] = numpy.real(l_coeffs[l]) + (1j) * 0.0\n",
    "                \n",
    "    vsh_B_coeffs = [ [ scale * (numpy.random.normal(0.0 , numpy.sqrt(variance[l-1])) + (1j) * numpy.random.normal(0.0 , numpy.sqrt(variance[l-1]))) for m in range (-l,l+1)] for l in range (1,len(variance)+1)]\n",
    "\n",
    "    for l , l_coeffs in enumerate(vsh_B_coeffs):\n",
    "        if l > 0:\n",
    "            for m in range (-l,l+1):\n",
    "                if m < 0:\n",
    "                    l_coeffs[m+l] = ((-1)**(-m)) * numpy.conj (l_coeffs[-m+l])\n",
    "                elif m == 0:\n",
    "                    l_coeffs[l] = numpy.real(l_coeffs[l]) + (1j) * 0.0\n",
    "\n",
    "    model_pm = generate_model ( vsh_E_coeffs , vsh_B_coeffs , data.positions )\n",
    "    \n",
    "    data.proper_motions = model_pm\n",
    "\n",
    "    data.proper_motions_err = scale * numpy.ones(data.proper_motions_err.shape, dtype=None, order='C')\n",
    "    data.proper_motions_err_corr = numpy.zeros(data.proper_motions_err_corr.shape, dtype=None, order='C')\n",
    "    \n",
    "    return data\n",
    "\n",
    "data = generate_gr_bg (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def MollweideFunc (latitude, epsilon):\n",
    "    MollweideFunc = lambda alpha : 2 * alpha + numpy.sin(2 * alpha) - numpy.pi * numpy.sin ( latitude )\n",
    "        \n",
    "    alpha = fsolve(MollweideFunc, latitude, xtol=epsilon)\n",
    "        \n",
    "    return alpha[0]\n",
    "    \n",
    "def GeographicToMollweide (geographicPoints):\n",
    "    epsilon = 1e-6\n",
    "        \n",
    "    MollweidePoints = numpy.array(numpy.zeros(geographicPoints.shape))\n",
    "        \n",
    "    alpha = [MollweideFunc(lat, epsilon) if not numpy.isclose(numpy.absolute(lat), numpy.pi/2, rtol=epsilon, atol=0.0, equal_nan=False) else lat for lat in geographicPoints[:, 1]]\n",
    "    MollweidePoints[:, 0] = (2 * numpy.sqrt(2) / numpy.pi) * ( geographicPoints[:, 0] - numpy.pi ) * numpy.cos(alpha)\n",
    "    MollweidePoints[:, 1] = numpy.sqrt(2) * numpy.sin(alpha)\n",
    "        \n",
    "    return MollweidePoints\n",
    "    \n",
    "def tangent_geographic_to_Cartesian (points, dpoints):\n",
    "    initial_vectors = numpy.array(points, dtype='float128', copy=True, order='K', subok=False, ndmin=0)\n",
    "    dpoints = numpy.array(dpoints, dtype='float128', copy=True, order='K', subok=False, ndmin=0)\n",
    "    \n",
    "    end_vectors = initial_vectors + dpoints\n",
    "\n",
    "    initial_vectors = geographic_to_Cartesian (initial_vectors)\n",
    "    end_vectors = geographic_to_Cartesian (end_vectors)\n",
    "\n",
    "    t = numpy.reciprocal ( numpy.einsum ( 'ij,ij->i' , initial_vectors , end_vectors ) )\n",
    "    tangent_vectors = numpy.einsum ( 'ij,i->ij' , end_vectors , t ) - initial_vectors\n",
    "    \n",
    "    return tangent_vectors\n",
    "\n",
    "def tangent_geographic_to_Cartesian2 (points, dpoints):\n",
    "    tangent_vector = numpy.zeros ( ( len(points) , 3 ) , dtype = float)\n",
    "    \n",
    "    theta = numpy.pi / 2 - points[... , 1]\n",
    "    phi = points[... , 0]\n",
    "    \n",
    "    dtheta = - dpoints[... , 1]\n",
    "    dphi = dpoints[... , 0]\n",
    "    \n",
    "    tangent_vector[...,0] = numpy.cos (theta) * numpy.cos (phi) * dtheta - numpy.sin (theta) * numpy.sin (phi) * dphi\n",
    "    tangent_vector[...,1] = numpy.cos (theta) * numpy.sin (phi) * dtheta + numpy.sin (theta) * numpy.cos (phi) * dphi\n",
    "    tangent_vector[...,2] = - numpy.sin (theta) * dtheta\n",
    "    \n",
    "    return tangent_vector\n",
    "\n",
    "def uniform_points_on_sphere_from_data (data , N):\n",
    "    starting_point_ind = random.SystemRandom().randint (1 , len(data))\n",
    "\n",
    "    points_from_data = numpy.array([starting_point_ind])\n",
    "    pairwise_distances_to_data = data.dot(data[starting_point_ind].transpose())\n",
    "\n",
    "    for i in range(1, N):\n",
    "        k = pairwise_distances_to_data.argmin()\n",
    "\n",
    "        points_from_data = numpy.append(points_from_data, k)\n",
    "\n",
    "        new_distances_to_data = numpy.array(data.dot(data[k].transpose()))\n",
    "\n",
    "        pairwise_distances_to_data = numpy.maximum (pairwise_distances_to_data, new_distances_to_data)\n",
    "        \n",
    "    return (points_from_data)\n",
    "\n",
    "def switch_hemispheres_geographic_coords (points):\n",
    "    new_points = points.copy()\n",
    "    \n",
    "    new_points[...,0] = numpy.where ( points[...,0] < numpy.pi , points[...,0] + numpy.pi , points[...,0] - numpy.pi )\n",
    "    \n",
    "    return new_points\n",
    "\n",
    "# def simple_input_func (path):\n",
    "#     points = []\n",
    "    \n",
    "#     with open(path) as csvfile:\n",
    "#         reader = csv.reader ( csvfile )\n",
    "#         next ( reader )\n",
    "        \n",
    "#         for row in reader:\n",
    "#             ra = numpy.deg2rad ( float ( row[5] ) )\n",
    "#             dec = numpy.deg2rad ( float ( row[7] ) )\n",
    "            \n",
    "#             points.append ( [ ra , dec ] )\n",
    "    \n",
    "#     points = numpy.array ( points )\n",
    "#     return points\n",
    "\n",
    "# def simple_input_func_pm (path):\n",
    "#     points = []\n",
    "    \n",
    "#     with open(path) as csvfile:\n",
    "#         reader = csv.reader ( csvfile )\n",
    "#         next ( reader )\n",
    "        \n",
    "#         for row in reader:\n",
    "#             if row[12] == \"NULL\":\n",
    "#                 ra = numpy.nan\n",
    "#             else:\n",
    "#                 print(row[12])\n",
    "#                 ra = numpy.deg2rad ( float ( row[12] ) )\n",
    "                \n",
    "#             if row[14] == \"NULL\":\n",
    "#                 dec = numpy.nan\n",
    "#             else:\n",
    "#                 dec = numpy.deg2rad ( float ( row[14] ) )\n",
    "            \n",
    "#             points.append ( [ ra , dec ] )\n",
    "    \n",
    "#     points = numpy.array ( points )\n",
    "#     return points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
