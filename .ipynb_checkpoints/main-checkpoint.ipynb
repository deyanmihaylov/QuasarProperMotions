{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def MollweideFunc (latitude, epsilon):\n",
    "    MollweideFunc = lambda alpha : 2 * alpha + numpy.sin(2 * alpha) - numpy.pi * numpy.sin ( latitude )\n",
    "        \n",
    "    alpha = fsolve(MollweideFunc, latitude, xtol=epsilon)\n",
    "        \n",
    "    return alpha[0]\n",
    "    \n",
    "def GeographicToMollweide (geographicPoints):\n",
    "    epsilon = 1e-6\n",
    "        \n",
    "    MollweidePoints = numpy.array(numpy.zeros(geographicPoints.shape))\n",
    "        \n",
    "    alpha = [MollweideFunc(lat, epsilon) if not numpy.isclose(numpy.absolute(lat), numpy.pi/2, rtol=epsilon, atol=0.0, equal_nan=False) else lat for lat in geographicPoints[:, 1]]\n",
    "    MollweidePoints[:, 0] = (2 * numpy.sqrt(2) / numpy.pi) * ( geographicPoints[:, 0] - numpy.pi ) * numpy.cos(alpha)\n",
    "    MollweidePoints[:, 1] = numpy.sqrt(2) * numpy.sin(alpha)\n",
    "        \n",
    "    return MollweidePoints\n",
    "    \n",
    "def tangent_geographic_to_Cartesian (points, dpoints):\n",
    "    initial_vectors = numpy.array(points, dtype='float128', copy=True, order='K', subok=False, ndmin=0)\n",
    "    dpoints = numpy.array(dpoints, dtype='float128', copy=True, order='K', subok=False, ndmin=0)\n",
    "    \n",
    "    end_vectors = initial_vectors + dpoints\n",
    "\n",
    "    initial_vectors = geographic_to_Cartesian (initial_vectors)\n",
    "    end_vectors = geographic_to_Cartesian (end_vectors)\n",
    "\n",
    "    t = numpy.reciprocal ( numpy.einsum ( 'ij,ij->i' , initial_vectors , end_vectors ) )\n",
    "    tangent_vectors = numpy.einsum ( 'ij,i->ij' , end_vectors , t ) - initial_vectors\n",
    "    \n",
    "    return tangent_vectors\n",
    "\n",
    "def tangent_geographic_to_Cartesian2 (points, dpoints):\n",
    "    tangent_vector = numpy.zeros ( ( len(points) , 3 ) , dtype = float)\n",
    "    \n",
    "    theta = numpy.pi / 2 - points[... , 1]\n",
    "    phi = points[... , 0]\n",
    "    \n",
    "    dtheta = - dpoints[... , 1]\n",
    "    dphi = dpoints[... , 0]\n",
    "    \n",
    "    tangent_vector[...,0] = numpy.cos (theta) * numpy.cos (phi) * dtheta - numpy.sin (theta) * numpy.sin (phi) * dphi\n",
    "    tangent_vector[...,1] = numpy.cos (theta) * numpy.sin (phi) * dtheta + numpy.sin (theta) * numpy.cos (phi) * dphi\n",
    "    tangent_vector[...,2] = - numpy.sin (theta) * dtheta\n",
    "    \n",
    "    return tangent_vector\n",
    "\n",
    "def uniform_points_on_sphere_from_data (data , N):\n",
    "    starting_point_ind = random.SystemRandom().randint (1 , len(data))\n",
    "\n",
    "    points_from_data = numpy.array([starting_point_ind])\n",
    "    pairwise_distances_to_data = data.dot(data[starting_point_ind].transpose())\n",
    "\n",
    "    for i in range(1, N):\n",
    "        k = pairwise_distances_to_data.argmin()\n",
    "\n",
    "        points_from_data = numpy.append(points_from_data, k)\n",
    "\n",
    "        new_distances_to_data = numpy.array(data.dot(data[k].transpose()))\n",
    "\n",
    "        pairwise_distances_to_data = numpy.maximum (pairwise_distances_to_data, new_distances_to_data)\n",
    "        \n",
    "    return (points_from_data)\n",
    "\n",
    "def switch_hemispheres_geographic_coords (points):\n",
    "    new_points = points.copy()\n",
    "    \n",
    "    new_points[...,0] = numpy.where ( points[...,0] < numpy.pi , points[...,0] + numpy.pi , points[...,0] - numpy.pi )\n",
    "    \n",
    "    return new_points\n",
    "\n",
    "# def simple_input_func (path):\n",
    "#     points = []\n",
    "    \n",
    "#     with open(path) as csvfile:\n",
    "#         reader = csv.reader ( csvfile )\n",
    "#         next ( reader )\n",
    "        \n",
    "#         for row in reader:\n",
    "#             ra = numpy.deg2rad ( float ( row[5] ) )\n",
    "#             dec = numpy.deg2rad ( float ( row[7] ) )\n",
    "            \n",
    "#             points.append ( [ ra , dec ] )\n",
    "    \n",
    "#     points = numpy.array ( points )\n",
    "#     return points\n",
    "\n",
    "# def simple_input_func_pm (path):\n",
    "#     points = []\n",
    "    \n",
    "#     with open(path) as csvfile:\n",
    "#         reader = csv.reader ( csvfile )\n",
    "#         next ( reader )\n",
    "        \n",
    "#         for row in reader:\n",
    "#             if row[12] == \"NULL\":\n",
    "#                 ra = numpy.nan\n",
    "#             else:\n",
    "#                 print(row[12])\n",
    "#                 ra = numpy.deg2rad ( float ( row[12] ) )\n",
    "                \n",
    "#             if row[14] == \"NULL\":\n",
    "#                 dec = numpy.nan\n",
    "#             else:\n",
    "#                 dec = numpy.deg2rad ( float ( row[14] ) )\n",
    "            \n",
    "#             points.append ( [ ra , dec ] )\n",
    "    \n",
    "#     points = numpy.array ( points )\n",
    "#     return points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "\n",
    "class AstrometricDataframe:\n",
    "    def __init__(self): \n",
    "        self.positions = numpy.array ([])\n",
    "        self.positions_coord_system = \"\"\n",
    "\n",
    "        self.positions_err = numpy.array ([])\n",
    "\n",
    "        self.proper_motions = numpy.array ([])\n",
    "\n",
    "        self.proper_motions_err = numpy.array ([])\n",
    "        \n",
    "        self.proper_motions_err_corr = numpy.array ([])\n",
    "    \n",
    "\n",
    "def import_Gaia_data (path_to_Gaia_data):\n",
    "    dataset = pandas.read_csv(path_to_Gaia_data,\n",
    "                              sep=',',\n",
    "                              delimiter=None,\n",
    "                              header='infer',\n",
    "                              names=None,\n",
    "                              index_col=None,\n",
    "                              usecols=None,\n",
    "                              squeeze=False,\n",
    "                              prefix=None,\n",
    "                              mangle_dupe_cols=True,\n",
    "                              dtype=None,\n",
    "                              engine='python',\n",
    "                              converters=None,\n",
    "                              true_values=None,\n",
    "                              false_values=None,\n",
    "                              skipinitialspace=False,\n",
    "                              skiprows=None,\n",
    "                              skipfooter=0,\n",
    "                              nrows=None,\n",
    "                              na_values=None,\n",
    "                              keep_default_na=True,\n",
    "                              na_filter=True,\n",
    "                              verbose=False,\n",
    "                              skip_blank_lines=True,\n",
    "                              parse_dates=False,\n",
    "                              infer_datetime_format=False,\n",
    "                              keep_date_col=False,\n",
    "                              date_parser=None,\n",
    "                              dayfirst=False,\n",
    "                              iterator=False,\n",
    "                              chunksize=None,\n",
    "                              compression=None,\n",
    "                              thousands=None,\n",
    "                              decimal=b'.',\n",
    "                              lineterminator=None,\n",
    "                              quotechar='\"',\n",
    "                              quoting=0,\n",
    "                              doublequote=True,\n",
    "                              escapechar=None,\n",
    "                              comment=None,\n",
    "                              encoding=None,\n",
    "                              dialect=None,\n",
    "                              error_bad_lines=True,\n",
    "                              warn_bad_lines=True,\n",
    "                              delim_whitespace=False,\n",
    "                              low_memory=True,\n",
    "                              memory_map=False,\n",
    "                              float_precision=None)\n",
    "    \n",
    "    dropna_columns = ['ra',\n",
    "                     'dec',\n",
    "                     'ra_error',\n",
    "                     'dec_error',\n",
    "                     'pmra',\n",
    "                     'pmdec',\n",
    "                     'pmra_error',\n",
    "                     'pmdec_error',\n",
    "                     'pmra_pmdec_corr']\n",
    "\n",
    "    dataset.dropna(axis=0,\n",
    "                   how='any',\n",
    "                   thresh=None,\n",
    "                   subset=dropna_columns,\n",
    "                   inplace=True)\n",
    "    \n",
    "    new_dataframe = AstrometricDataframe()\n",
    "    \n",
    "    new_dataframe.positions = dataset.as_matrix ( columns = [ 'ra' , 'dec' ] )\n",
    "    new_dataframe.positions_coord_system = \"Geographic\"\n",
    "    \n",
    "    new_dataframe.positions_err = dataset.as_matrix ( columns = [ 'ra_error' , 'dec_error' ] )\n",
    "    \n",
    "    new_dataframe.proper_motions = dataset.as_matrix ( columns = [ 'pmra' , 'pmdec' ] )\n",
    "    \n",
    "    new_dataframe.proper_motions_err = dataset.as_matrix ( columns = [ 'pmra_error' , 'pmdec_error' ] )\n",
    "    \n",
    "    new_dataframe.proper_motions_err_corr = dataset.as_matrix ( columns = [ 'pmra_pmdec_corr' ] )\n",
    "    \n",
    "    return new_dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data3 = import_Gaia_data(\"data/type2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data conversion and coordinates change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy\n",
    "import random\n",
    "import time\n",
    "\n",
    "from scipy.optimize import fsolve\n",
    "\n",
    "def deg_to_rad(degree_vals):\n",
    "    return numpy.deg2rad (degree_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change positions from deg to rad\n",
    "\n",
    "data3.positions = deg_to_rad (data3.positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change proper motions from mas/yr to rad/s\n",
    "\n",
    "data3.proper_motions = data3.proper_motions * 1.5362818500441604e-16\n",
    "data3.proper_motions_err = data3.proper_motions_err * 1.5362818500441604e-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change proper motions from (ra,dec) to Cartesian coordinates\n",
    "\n",
    "#data3.proper_motions = tangent_geographic_to_Cartesian2 (data3.positions , data3.proper_motions)\n",
    "#data3.proper_motions_err = tangent_geographic_to_Cartesian2 (data3.positions , data3.proper_motions_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change positions from (ra,dec) to Cartesian\n",
    "\n",
    "#data3.positions = geographic_to_Cartesian (data3.positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating random VSH coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from VectorSphericalHarmonics import VectorSphericalHarmonicE, VectorSphericalHarmonicB\n",
    "\n",
    "def random_aQlm_coeffs ( lmax , lower_bound , upper_bound ):\n",
    "    negative_coeffs = [ [ random.uniform ( lower_bound , upper_bound ) + 1j * random.uniform ( lower_bound , upper_bound ) for m in range ( -l , 0 ) ] for l in range ( 1 , lmax + 1 ) ]\n",
    "    \n",
    "    coeffs = [ [ negative_coeffs[ l-1 ][ m+l ] if m < 0\n",
    "                 else random.uniform ( lower_bound , upper_bound ) + 1j * 0.0 if m == 0\n",
    "                 else (-1) ** m * numpy.conj ( negative_coeffs[ l-1 ][ m-l ] )\n",
    "                 for m in range ( -l , l+1 ) ] for l in range ( 1 , lmax + 1 ) ]\n",
    "    \n",
    "    return coeffs\n",
    "\n",
    "def random_vsh_coeffs ( lmax , lower_bound , upper_bound):\n",
    "    vsh_E_coeffs = random_aQlm_coeffs ( lmax , lower_bound , upper_bound )\n",
    "    vsh_B_coeffs = random_aQlm_coeffs ( lmax , lower_bound , upper_bound )\n",
    "        \n",
    "    return vsh_E_coeffs , vsh_B_coeffs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vsh_E_coeffs , vsh_B_coeffs = random_vsh_coeffs ( 2 , -1.0e-15 , 1.0e-15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def geographic_to_Cartesian (points):\n",
    "    if len ( points.shape ) == 1:\n",
    "        nrows = 1\n",
    "    else:\n",
    "        nrows = points.shape[0]\n",
    "        \n",
    "    new_points = numpy.zeros ( ( len(points) , 3 ))\n",
    "    \n",
    "    theta = numpy.pi / 2 - points[... , 1]\n",
    "    phi = points[... , 0]\n",
    "    \n",
    "    new_points[...,0] = numpy.sin ( theta ) * numpy.cos ( phi )\n",
    "    new_points[...,1] = numpy.sin ( theta ) * numpy.sin ( phi )\n",
    "    new_points[...,2] = numpy.cos ( theta )\n",
    "    \n",
    "    if len ( points.shape ) == 1:\n",
    "        return new_points[0]\n",
    "    else:\n",
    "        return new_points\n",
    "\n",
    "def tangent_Cartesian_to_geographic (points , dpoints):\n",
    "    if points.ndim == 1:\n",
    "        tangent_vector = numpy.zeros ( ( 2 ) , dtype = float)\n",
    "    else:\n",
    "        tangent_vector = numpy.zeros ( ( len(points) , 2 ) , dtype = float)\n",
    "    \n",
    "    x = points[... , 0]\n",
    "    y = points[... , 1]\n",
    "    z = points[... , 2]\n",
    "    \n",
    "    dx = dpoints[... , 0]\n",
    "    dy = dpoints[... , 1]\n",
    "    dz = dpoints[... , 2]\n",
    "    \n",
    "    tangent_vector[... , 0] = dz / ( numpy.sqrt ( 1 - z ** 2 ) )\n",
    "    tangent_vector[... , 1] = ( x * dy - y * dx ) / ( x ** 2 + y ** 2 )\n",
    "    \n",
    "    return tangent_vector\n",
    "\n",
    "def generate_model ( vsh_E_coeffs , vsh_B_coeffs , positions ):\n",
    "    lmax = min ( len( vsh_E_coeffs ) , len( vsh_B_coeffs ) )\n",
    "\n",
    "    positions_Cartesian = geographic_to_Cartesian ( positions )\n",
    "    \n",
    "    v_E = [ sum( [ sum( [ vsh_E_coeffs[ l-1 ][ m+l ] * VectorSphericalHarmonicE ( l , m , pos ) for m in range ( -l , l+1 ) ] ) for l in range ( 1 , lmax + 1 ) ] ) for pos in positions_Cartesian ]\n",
    "    \n",
    "    v_B = [ sum( [ sum( [ vsh_B_coeffs[ l-1 ][ m+l ] * VectorSphericalHarmonicB ( l , m , pos ) for m in range ( -l , l+1 ) ] ) for l in range ( 1 , lmax + 1 ) ] ) for pos in positions_Cartesian ]\n",
    "    \n",
    "    numpy.testing.assert_almost_equal(numpy.imag(v_E).sum(), 0.)\n",
    "    numpy.testing.assert_almost_equal(numpy.imag(v_B).sum(), 0.)\n",
    "    \n",
    "    v_Q = numpy.real ( numpy.add ( numpy.array ( v_E ) , numpy.array ( v_B ) ) )\n",
    "        \n",
    "    return tangent_Cartesian_to_geographic ( positions_Cartesian , v_Q )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = generate_model (vsh_E_coeffs , vsh_B_coeffs , data3.positions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def covariant_matrix ( errors , corr ):\n",
    "    covariant_matrix = numpy.einsum ( '...i,...j->...ij' , errors , errors )\n",
    "    \n",
    "    covariant_matrix[...,0,1] = covariant_matrix[...,1,0] = numpy.multiply ( covariant_matrix[...,1,0] , corr.flatten() )\n",
    "    return covariant_matrix\n",
    "\n",
    "def R_values ( pm , pm_err , pm_err_corr , model ):\n",
    "    covariant_matrices = covariant_matrix ( pm_err , pm_err_corr )\n",
    "    \n",
    "    M = pm - model\n",
    "    \n",
    "    R_values = numpy.einsum ( '...i,...ij,...j->...' , M , numpy.linalg.inv ( covariant_matrices ) , M ) \n",
    "        \n",
    "    return R_values\n",
    "\n",
    "def compute_log_likelihood ( R_values ):\n",
    "    log_likelihood = numpy.log ( ( 1. - numpy.exp ( - R_values ** 2 / 2.) ) / ( R_values ** 2 ) ).sum()\n",
    "    \n",
    "    return log_likelihood\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "R = R_values ( data3.proper_motions , data3.proper_motions_err , data3.proper_motions_err_corr , model)\n",
    "\n",
    "u = compute_log_likelihood (R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to fit with Chris' Python Particle Swarm Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(-4.051820432552491e-15+3.9019242260068935e-15j), 1.0962514403063393e-15, (-2.1989423583619877e-15+1.5898338470668441e-15j)], [(-4.005078512411002e-15+8.295448331349153e-15j), (7.242640554933391e-15-7.022912072523901e-15j), 7.407801139573162e-16, (-5.394325112551346e-15+9.140480362437914e-15j), (-3.866305737185125e-15-1.4372516862603125e-15j)], [(9.905129645633751e-15-1.2045374537853373e-15j), (-4.591105300268807e-15+1.6206152525940413e-16j), (-1.4651795083578574e-15-2.3169299929584544e-15j), 2.00678369665432e-15, (8.961771647529057e-15-3.435506878025172e-15j), (-2.777910391239437e-15-6.516987950664284e-15j), (-7.6636705852496e-15+1.4687411361732721e-15j)]]\n",
      "[[(-4.86130129408709e-15+9.746539081626012e-15j), 1.7986352892125863e-15, (7.270009629945627e-15-2.0299349018935748e-15j)], [(-3.490502032823688e-15-1.715352162705143e-15j), (-4.862114468593031e-15-5.833711376264423e-15j), -8.561320209723371e-15, (4.63599678108349e-15+5.5491893756491685e-15j), (-8.754921473469426e-15+7.541946507125891e-15j)], [(-6.06436128305591e-15-2.044497183993133e-15j), (-5.9212581389419875e-15+9.964970394079958e-15j), (-8.91459631296432e-16+9.983613229563222e-15j), 1.9283964172857136e-15, (8.6417214312764e-15+5.626168777821809e-16j), (2.5465820280464594e-15-9.176476560049593e-15j), (7.344734390929407e-15-8.865020851237762e-15j)]]\n",
      "[[(-3.953198753144274e-15+4.0240320254038886e-15j), 1.1325412971204566e-15, (-2.273398990741118e-15+1.6302270539766253e-15j)], [(-4.059246270266352e-15+8.492088518425572e-15j), (7.370694386535324e-15-7.020836389062327e-15j), 5.679931021086122e-16, (-5.277176523961337e-15+9.07701996218693e-15j), (-3.871678896744584e-15-1.3938349621385926e-15j)], [(9.72472305919479e-15-1.2401940439975548e-15j), (-4.784025108512949e-15+3.4526139011449444e-16j), (-1.6326869608705156e-15-2.162699768952619e-15j), 1.887776110162597e-15, (9.04236558956181e-15-3.460743289079959e-15j), (-2.9453038363439615e-15-6.5909092369568205e-15j), (-7.852393563608727e-15+1.5530218701371385e-15j)]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fff38954ec7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m                 EnergyTol = 1.0e-8)\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mmyswarm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/deyanmihaylov/anaconda/lib/python3.5/site-packages/PySO/Swarm.py\u001b[0m in \u001b[0;36mRun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mContinueCondition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvolveSwarm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEvolutionCounter\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_periodic_checkpoint\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/deyanmihaylov/anaconda/lib/python3.5/site-packages/PySO/Swarm.py\u001b[0m in \u001b[0;36mEvolveSwarm\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;31m# Update function values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mValues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_posterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;31m# Update particle's best known position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/deyanmihaylov/anaconda/lib/python3.5/site-packages/PySO/Model.py\u001b[0m in \u001b[0;36mlog_posterior\u001b[0;34m(self, param)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mlog_prior\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlog_likelihood\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \"\"\"\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-fff38954ec7a>\u001b[0m in \u001b[0;36mlog_likelihood\u001b[0;34m(self, param)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvsh_E_coeffs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_model\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvsh_E_coeffs\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvsh_B_coeffs\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdata3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_R\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mdata3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproper_motions\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdata3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproper_motions_err\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdata3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproper_motions_err_corr\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlog_likelhood_fun\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2ea5c153bc8f>\u001b[0m in \u001b[0;36mgenerate_model\u001b[0;34m(vsh_E_coeffs, vsh_B_coeffs, positions)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mv_B\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlm_coeff\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mVectorSphericalHarmonicB\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mpoint_Cart\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_almost_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_E\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/deyanmihaylov/Desktop/Astrometry/Quasars/QuasarProperMotions/VectorSphericalHarmonics.py\u001b[0m in \u001b[0;36mVectorSphericalHarmonicB\u001b[0;34m(l, m, n)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mc2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0ml\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         DY_Dtheta = -( c1 * NormalisedAssociatedLegendrePolynomial ( l , m-1 , x ) - \n\u001b[0m\u001b[1;32m    130\u001b[0m                      c2 * NormalisedAssociatedLegendrePolynomial ( l , m+1 , x ) ) * np.exp ( (1j) * m * phi )\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import PySO\n",
    "\n",
    "class QSO_VSH_fit(PySO.Model):\n",
    "\n",
    "    Lmax = 3\n",
    "    \n",
    "    names=[]\n",
    "    for L in numpy.arange(1, Lmax+1):\n",
    "        for m in numpy.arange(-L, L+1):\n",
    "            if m==0:\n",
    "                names += ['Ra^E_{0}_{1}'.format(L,m)]\n",
    "                names += ['Ra^B_{0}_{1}'.format(L,m)]\n",
    "            else:\n",
    "                names += ['Ra^E_{0}_{1}'.format(L,m)]\n",
    "                names += ['Ra^B_{0}_{1}'.format(L,m)]\n",
    "                names += ['Ia^E_{0}_{1}'.format(L,m)]\n",
    "                names += ['Ia^B_{0}_{1}'.format(L,m)]\n",
    "    \n",
    "    bounds = [ [-1.0e-14,1.0e-14] for i in range(len(names))]\n",
    "    \n",
    "\n",
    "    def log_likelihood(self, param):\n",
    "        \n",
    "        vsh_E_coeffs = [ [ \n",
    "                            param['Ra^E_{0}_{1}'.format(L,m)] \n",
    "                            if m==0 else \n",
    "                            param['Ra^E_{0}_{1}'.format(L,m)]+(1j)*param['Ia^E_{0}_{1}'.format(L,m)]\n",
    "                          for m in numpy.arange(-L, L+1) ] for L in numpy.arange(1, self.Lmax+1)]\n",
    "        \n",
    "        vsh_B_coeffs = [ [ \n",
    "                            param['Ra^B_{0}_{1}'.format(L,m)] \n",
    "                            if m==0 else \n",
    "                            param['Ra^B_{0}_{1}'.format(L,m)]+(1j)*param['Ia^B_{0}_{1}'.format(L,m)]\n",
    "                          for m in numpy.arange(-L, L+1) ] for L in numpy.arange(1, self.Lmax+1)]\n",
    "        \n",
    "        print (vsh_E_coeffs)\n",
    "        \n",
    "        model = generate_model (vsh_E_coeffs , vsh_B_coeffs , data3.positions)\n",
    "        R = generate_R ( data3.proper_motions , data3.proper_motions_err , data3.proper_motions_err_corr , model)\n",
    "        return log_likelhood_fun (R)\n",
    "    \n",
    "mymodel = QSO_VSH_fit()\n",
    "\n",
    "NumParticles = 2\n",
    "\n",
    "myswarm = PySO.Swarm(mymodel,\n",
    "                NumParticles,\n",
    "                Omega = 0.01,\n",
    "                PhiP = 0.1,\n",
    "                PhiG = 0.1,\n",
    "                EnergyTol = 1.0e-8)\n",
    "\n",
    "myswarm.Run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data3.proper_motions_err_corr\n",
    "\n",
    "def tangent_err_to_Cartesrian (positions , pms , pm_errs , pm_err_corr):\n",
    "    for i , point in enumerate (positions):\n",
    "        ra = point[0]\n",
    "        dec = point[1]\n",
    "        \n",
    "        pmra_err = pm_errs[i,0]\n",
    "        pmdec_err = pm_errs[i,1]\n",
    "        \n",
    "        pmra_pmdec_err_corr = pm_err_corr[i,0]\n",
    "        \n",
    "        R = numpy.array ( [ [ - numpy.cos ( dec ) * numpy.sin ( ra ) , - numpy.sin ( dec ) * numpy.cos ( ra ) ] ,\n",
    "                            [ numpy.cos ( dec) * numpy.sin ( ra ) , - numpy.sin ( dec ) * numpy.sin ( ra ) ] ,\n",
    "                            [ - numpy.cos ( dec ) , 0 ] ] )\n",
    "        \n",
    "        pm_err_matrix = numpy.array ( [ [ pmra_err , numpy.sqrt ( numpy.abs (pmra_err * pmdec_err * pmra_pmdec_err_corr ) ) ] ,\n",
    "                                        [ numpy.sqrt ( numpy.abs (pmra_err * pmdec_err * pmra_pmdec_err_corr ) ) , pmdec_err ] ] )\n",
    "        \n",
    "        pm_err_matrix_Cartesian = R.dot(pm_err_matrix).dot(R.transpose())\n",
    "        \n",
    "#         print (numpy.linalg.eig(pm_err_matrix_Cartesian))\n",
    "    \n",
    "tangent_err_to_Cartesrian (data3.positions , data3.proper_motions , data3.proper_motions_err , data3.proper_motions_err_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Ellipse\n",
    "\n",
    "def plot_pm_err_ellipse (pm , pm_err , pm_err_corr):\n",
    "    i = 575\n",
    "    \n",
    "    covariance_matrix = numpy.array ( [ [ pm_err[i,0] * pm_err[i,0] , pm_err_corr[i] * pm_err[i,0] * pm_err[i,1] ],\n",
    "                                        [ pm_err_corr[i] * pm_err[i,1] * pm_err[i,0] , pm_err[i,1] * pm_err[i,1] ] ] )\n",
    "    \n",
    "    eigenvalues , eigenvectors = numpy.linalg.eig ( covariance_matrix )\n",
    "    \n",
    "    box_size = numpy.max ( [ numpy.sqrt(eigenvalues[0]) , numpy.sqrt(eigenvalues[1]) , numpy.linalg.norm ( pm[i] ) ] )\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.axes().set_aspect('equal')\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    plt.xlim ( [ pm[i,0] - 1.5 * box_size , pm[i,0] + 1.5 * box_size ] )\n",
    "    plt.ylim ( [ pm[i,1] - 1.5 * box_size , pm[i,1] + 1.5 * box_size ] )\n",
    "    \n",
    "    plt.arrow(0 , 0 , pm[i,0] , pm[i,1] , width=box_size * 1e-3 , head_width=box_size * 0.5e-1, head_length=box_size * 1e-1 , color='k')\n",
    "            \n",
    "    plt.arrow(pm[i,0] , pm[i,1] , numpy.sqrt(eigenvalues[0]) * eigenvectors[0,0] , numpy.sqrt(eigenvalues[0]) * eigenvectors[0,1] , width=box_size * 1e-3 , head_width=box_size * 0.5e-1, head_length=box_size * 1e-1 , color='orange')\n",
    "    \n",
    "    plt.arrow(pm[i,0] , pm[i,1] , numpy.sqrt(eigenvalues[1]) * eigenvectors[1,0] , numpy.sqrt(eigenvalues[1]) * eigenvectors[1,1] , width=box_size * 1e-3 , head_width=box_size * 0.5e-1, head_length=box_size * 1e-1 , color='y')\n",
    "    \n",
    "    angle = - numpy.rad2deg ( numpy.arctan2 ( eigenvectors[1,0] , eigenvectors[1,1] ) )\n",
    "            \n",
    "    ell = Ellipse(xy=(pm[i,0] , pm[i,1]), width=2 * numpy.sqrt(eigenvalues[0]), height=2 * numpy.sqrt(eigenvalues[1]), angle = angle)\n",
    "    \n",
    "    ax.add_patch(ell)\n",
    "    ax.set_aspect('equal')\n",
    "            \n",
    "    plt.show()\n",
    "    \n",
    "    return covariance_matrix\n",
    "\n",
    "print (plot_pm_err_ellipse ( data3.proper_motions , data3.proper_motions_err , data3.proper_motions_err_corr ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_pos = type3_sample\n",
    "final_pos = type3_sample + type3_sample_pm\n",
    "\n",
    "lines_to_plot = []\n",
    "\n",
    "for i,_ in enumerate (initial_pos):\n",
    "    longs = numpy.linspace(initial_pos[i,0], final_pos[i,0], 10)\n",
    "    lats = numpy.linspace(initial_pos[i,1], final_pos[i,1], 10)\n",
    "    \n",
    "    line_m = GeographicToMollweide ( numpy.array ( [longs , lats] ).transpose() )\n",
    "    \n",
    "    lines_to_plot.append( line_m.transpose() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_pos_m = GeographicToMollweide ( initial_pos )\n",
    "final_pos_m = GeographicToMollweide ( final_pos )\n",
    "diff_m = final_pos_m - initial_pos_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "t = numpy.linspace (0, 2 * numpy.pi, 100)\n",
    "plt.plot ( 2 * numpy.sqrt(2) * numpy.cos(t) , numpy.sqrt(2) * numpy.sin(t) , linewidth=0.5 )\n",
    "\n",
    "for i,_ in enumerate(initial_pos_m):\n",
    "    plt.arrow( initial_pos_m[i,0] , initial_pos_m[i,1] , diff_m[i,0] , diff_m[i,1] , head_width=0.025, head_length=0.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spherepy as sp\n",
    "c = sp.random_coefs(4, 4) # generate some random coefficients\n",
    "print (type(c))\n",
    "# sp.pretty_coefs(c)\n",
    "# p = sp.ispht(c, 50, 50) # inverse spherical transform to pattern\n",
    "# sp.plot_sphere_mag(p) # plot the magnitude of the pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diff_m.argmin(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# look up units"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
